{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe35c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel, SpectralMixtureKernel, LinearKernel, PeriodicKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import GammaPrior\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.exceptions import BadInitialCandidatesWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "df964bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the model\n",
    "\n",
    "class ExactGPModel(ExactGP,GPyTorchModel):\n",
    "    \n",
    "    _num_outputs = 1\n",
    "    \n",
    "    def __init__(self,train_x,train_y):\n",
    "        super().__init__(train_x,train_y.squeeze(-1),GaussianLikelihood())\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = ScaleKernel(SpectralMixtureKernel(5,1) + RBFKernel(train_x.shape[-1]) \n",
    "                                       \n",
    "                                       )\n",
    "        self.to(train_x)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        \n",
    "        return MultivariateNormal(mean_x,covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c634636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize the model\n",
    "def Initialize_model(train_x,train_y,state_dict=None):\n",
    "    model = ExactGPModel(train_x,train_y)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood,model)\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model,mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7f47c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_query_point(model,rem_x):\n",
    "    model.eval()\n",
    "    model.likelihood.eval()\n",
    "    \n",
    "    var = model.likelihood(model(rem_x)).variance\n",
    "    ind = torch.argmax(var)\n",
    "    \n",
    "    return ind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "874d49dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   1/1\n",
      "Epoch  10/10 - Loss:-0.440\n",
      "Epoch  10/10 - Loss:-0.249\n",
      "Epoch  10/10 - Loss:-0.036\n",
      "Epoch  10/10 - Loss:-0.088\n",
      "Epoch  10/10 - Loss:-0.116\n",
      "Epoch  10/10 - Loss:-0.325\n",
      "Epoch  10/10 - Loss:-0.435\n",
      "Epoch  10/10 - Loss:-0.632\n",
      "Epoch  10/10 - Loss:-0.245\n",
      "Epoch  10/10 - Loss:-0.064\n",
      "Epoch  10/10 - Loss:0.160\n",
      "Epoch  10/10 - Loss:0.083\n",
      "Epoch  10/10 - Loss:0.199\n",
      "Epoch  10/10 - Loss:0.209\n",
      "Epoch  10/10 - Loss:0.177\n",
      "Epoch  10/10 - Loss:0.160\n",
      "Epoch  10/10 - Loss:0.105\n",
      "Epoch  10/10 - Loss:0.425\n",
      "Epoch  10/10 - Loss:0.407\n",
      "Epoch  10/10 - Loss:0.385\n",
      "Epoch  10/10 - Loss:0.489\n",
      "Epoch  10/10 - Loss:0.478\n",
      "Epoch  10/10 - Loss:0.462\n",
      "Epoch  10/10 - Loss:0.462\n",
      "Epoch  10/10 - Loss:0.660\n",
      "Epoch  10/10 - Loss:0.641\n",
      "Epoch  10/10 - Loss:0.624\n",
      "Epoch  10/10 - Loss:0.647\n",
      "Epoch  10/10 - Loss:0.630\n",
      "Epoch  10/10 - Loss:0.619\n",
      "Epoch  10/10 - Loss:0.604\n",
      "Epoch  10/10 - Loss:0.626\n",
      "Epoch  10/10 - Loss:0.636\n",
      "Epoch  10/10 - Loss:0.622\n",
      "Epoch  10/10 - Loss:0.610\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore',category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "\n",
    "def fit(x,y,verbose=True):\n",
    "    np.random.seed(42)\n",
    "    # Training data for working model--> need replace with out original data\n",
    "    l = int(torch.floor(torch.tensor(0.8*114)).item())\n",
    "    scaler = StandardScaler()\n",
    "    train_x = x[5:l]\n",
    "    train_y = y[5:l]\n",
    "\n",
    "    train_x = torch.Tensor(scaler.fit_transform(train_x))\n",
    "\n",
    "    test_x = torch.Tensor(scaler.transform(x[l:]))\n",
    "    test_y = y[l:]\n",
    "\n",
    "    train_dataset = TensorDataset(train_x,train_y)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,batch_size=10,shuffle=True)\n",
    "\n",
    "    # Initialize the model\n",
    "    train_x_al = train_x[:5]\n",
    "    train_y_al = train_y[:5]\n",
    "    model_al,mll_al = Initialize_model(train_x_al,train_y_al)\n",
    "    model_al.state_dict()\n",
    "    model_al.train()\n",
    "\n",
    "    for b,(rem_x,rem_y) in enumerate(train_loader):\n",
    "    \n",
    "        print(f\"Batch {b+1:>3}\")\n",
    "        N_trails = len(rem_x)\n",
    "\n",
    "    \n",
    "        for i in range(N_trails):\n",
    "        \n",
    "            ind = next_query_point(model_al,rem_x)\n",
    "            new_x = rem_x[ind]\n",
    "            new_y = rem_y[ind]\n",
    "        \n",
    "    \n",
    "            rem_x = torch.cat((rem_x[:ind],rem_x[ind+1:]))\n",
    "            rem_y = torch.cat((rem_y[:ind],rem_y[ind+1:]))\n",
    "        \n",
    "        \n",
    "            # update the training points \n",
    "            train_x_al = torch.cat((train_x_al,new_x.reshape(1,1)))\n",
    "            train_y_al = torch.cat((train_y_al,new_y.reshape(1,1)))\n",
    "        \n",
    "            # reinitiate the model\n",
    "            model_al,mll_al = Initialize_model(train_x_al,train_y_al,model_al.state_dict())\n",
    "        \n",
    "            fit_gpytorch_model(mll_al)\n",
    "        \n",
    "            \n",
    "            optimizer = torch.optim.Adam(model_al.parameters(),lr=0.01)\n",
    "        \n",
    "            epochs = 10\n",
    "        \n",
    "            model_al.train()\n",
    "        \n",
    "            for epoch in range(epochs):\n",
    "            \n",
    "            \n",
    "                # predicting on forward pass\n",
    "                output = model_al(train_x_al)\n",
    "            \n",
    "                # compute negative marginal log likelihood\n",
    "            \n",
    "                loss = -mll_al(output,model_al.train_targets)\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "                loss.backward()\n",
    "            \n",
    "                if (epoch + 1)%10 == 0 and verbose:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch+1:>3}/{epochs} - Loss:{loss.item():>4.3f},lengthscale:{model_al.covar_module.base_kernel.lengthscale.item()}\")\n",
    "            \n",
    "                optimizer.step()\n",
    "    model_al.eval()\n",
    "    model_al.likelihood.eval()\n",
    "    \n",
    "    predictions = model_al.likelihood(model_al(test_x))\n",
    "    \n",
    "    return test_y, predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e703e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_avg = pd.read_csv('cosine_weighted_average.csv')\n",
    "total_x = torch.linspace(1901,2014,114).reshape(-1,1).double()\n",
    "total_y = torch.tensor(cw_avg.values).reshape(-1,1).double()\n",
    "actual_y_nor, predicted_y_nor = fit(total_x,total_y,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(actual_y_nor-predicted_y_nor.mean).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ebff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(actual_y_nor-predicted_y_nor.mean)/actual_y_nor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834013ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = [25,40,50,75]\n",
    "dy = [10,20,30,40,50]\n",
    "\n",
    "for i in op:\n",
    "    print('optimal_locations:',i)\n",
    "    df = pd.read_table('absolute_error_op_'+str(i)+'_rs.dat',sep='\\s+',\n",
    "                      header=None)\n",
    "    df.columns = [str(j) for j in range(5)]\n",
    "    for k in range(5):\n",
    "        df_x = pd.read_csv('OA_evaluated_using_optimal_subset_for_duration_'+str(dy[k])+'.csv')\n",
    "        print('duration of years:',dy[k])\n",
    "        total_x = df_x[str(int(20*i))+' locations'].values.reshape(-1,1)\n",
    "        assert(total_x.shape==(114,1))\n",
    "        total_y = torch.tensor(df[str(k)].values).reshape(-1,1).double()\n",
    "        assert(total_y.shape==(114,1))\n",
    "        actual_y, predicted_y = fit(total_x,total_y,verbose=False)\n",
    "        assert(len(actual_y)==23)\n",
    "        assert(len(predicted_y.mean)==23)\n",
    "        con_cat = torch.cat((predicted_y.mean.reshape((-1,1)),actual_y.reshape((-1,1))),dim=1)\n",
    "        com_df = pd.DataFrame(con_cat.detach().numpy(),index=[str(i) for i in range(1992,2015,1)],\n",
    "                     columns=['observed_y','actual_y'])\n",
    "        com_df.to_csv('predicted_SMK_'+str(dy[k])+'_years_'+str(i)+'_op_rs_with_input_cbar.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03767e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_abs_err = {'10 years':[],'20 years':[],'30 years':[],'40 years':[],'50 years':[]}\n",
    "dict_rel_err = {'10 years':[],'20 years':[],'30 years':[],'40 years':[],'50 years':[]}\n",
    "\n",
    "for j in dy:\n",
    "    for i in op:\n",
    "        inputs = pd.read_csv('OA_evaluated_using_optimal_subset_for_duration_'+str(j)+'.csv')[str(int(20*i))+' locations']\n",
    "        error = pd.read_csv('predicted_SMK_'+str(j)+'_years_'+str(i)+'_op_rs_with_input_cbar.dat')\n",
    "        corrected = inputs.values.reshape(-1,1)[-23:,0:] + error['observed_y'].values.reshape(-1,1)\n",
    "        true_values = cw_avg['cw_avg'].iloc[-23:].values.reshape(-1,1)\n",
    "        absolute_error = abs(true_values-corrected)\n",
    "        assert(len(absolute_error)==len(true_values))\n",
    "        relative_error = absolute_error/true_values\n",
    "        assert(len(relative_error)==len(true_values))\n",
    "        dict_abs_err[str(j)+' years'].append(np.mean(absolute_error))\n",
    "        dict_rel_err[str(j)+' years'].append(np.mean(relative_error))\n",
    "#         print(f'''mean absolute error for {i*20} optimal \n",
    "#         locations considering {j} years of data is {np.mean(absolute_error)}''')\n",
    "#         print(f'''mean relative error for {i*20} optimal \n",
    "#         locations considering {j} years of data is {np.mean(relative_error)}''')\n",
    "                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
